{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Isotropic reconstruction training using isotrpopic mouse liver volume\n",
    "This notebook demonstrates training a vEMDiffuse-i model for a 3D isotropic reconstruction task with isotropic trainign data. Note that training a neural network for actual use should be done with **more training time and more training data** as used here.\n",
    "\n",
    "The demo data in this tutorial is downloaded from [Openorganelle Mouse Liver Dataset](https://openorganelle.janelia.org/datasets/jrc_mus-liver). The pixel size is 8 nm x 8 nm x 8 nm. The training objective is to istotropic reconstruction from anisotropic volume with a pixel size of 8 nm x 8 nm x 48 nm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Runtime Type on Google Colab\n",
    "\n",
    "Set the Runtime type: Go to Runtime -> Change the Runtime type\n",
    "\n",
    "Runtime type: Python 3 (Python 3 is programming language in which this program is written)\n",
    "\n",
    "Accelator: GPU (Graphics processing unit (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and install EMDiffuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Luchixiang/EMDiffuse\n",
    "%cd EMDiffuse/\n",
    "!pip install image_registration\n",
    "!pip install warmup_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following line if you run the notebook on local computer after clone the github repository. Igore it if you run the notebook on google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luchixiang/Downloads/hku/phd/EMDiffuse\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/luchixiang/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('RAFT/core')\n",
    "from RAFT.core.raftConfig import RaftConfig\n",
    "from RAFT.core.register import registration\n",
    "import urllib\n",
    "import zipfile\n",
    "import glob\n",
    "from tifffile import imread, imwrite\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Demo Data\n",
    "The example data consists of 24 continous layers from Openorganelle Mouse Liver Dataset. Please note that the model need more data to have a good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2c87d7c8b689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Here we only download the demo training datsaset, to download the whole dataset, replace the url with https://zenodo.org/records/10205819/files/EMDiffuse_dataset.zip?download=1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Since the training Dataset is large, it may takes about 5 minutes to download the whole dataset and 1 minute to extract them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('./dataset'):\n",
    "    os.mkdir('./dataset')\n",
    "\n",
    "# Here we only download the demo training datsaset, to download the whole dataset, replace the url with https://zenodo.org/records/10205819/files/EMDiffuse_dataset.zip?download=1.\n",
    "# Since the training Dataset is large, it may takes about 5 minutes to download the whole dataset and 1 minute to extract them.\n",
    "zipPath=\"dataset/vEMDiffusei_data_demo.zip\"\n",
    "if not os.path.exists(zipPath):\n",
    "    #download and unzip data\n",
    "    data = urllib.request.urlretrieve('https://zenodo.org/records/10669066/files/vEMDiffusei_dataset_demo.zip?download=1', zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset/vEMDiffusei_data_demo'\n",
    "example_image_layer0 = imread(os.path.join(subdir[0], '0.tif'))\n",
    "example_image_layer1 = imread(os.path.join(subdir[0], '1.tif'))\n",
    "example_image_layer23 = imread(os.path.join(subdir[0], '23.tif'))\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(example_image_layer0, cmap='gray')\n",
    "plt.title('Layer 1')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(example_image_layer1, cmap='gray')\n",
    "plt.title('Layer 2')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(example_image_layer24, cmap='gray')\n",
    "plt.title('Layer 24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.praser as Praser\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from core.logger import VisualWriter, InfoLogger\n",
    "import core.praser as Praser\n",
    "import core.util as Util\n",
    "from data import define_dataloader\n",
    "from models import create_EMDiffuse\n",
    "from emdiffuse_conifg import EMDiffuseConfig\n",
    "from run import main_worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMDiffuse Model\n",
    "Before we construct the actual vEMDiffuse-i model, we have to define its configuration via a Config object, which includesï¼š\n",
    "\n",
    "- path: The dataset path of cropped patches.\n",
    "- lr: learning rate. \n",
    "- config: Some basic parameters of the model, including the network architecutre, loss, noise scheduler, dataset configuration, learning rate.\n",
    "\n",
    "- batch_size: Training batch size on every gpu. \n",
    "- mean: Diffusion model samples one plausible solution from the learned solution distribution. Mean denotes the number of outputs you want to generate and average. \n",
    "- phase: run train or test.\n",
    "\n",
    "- z_times: axial resolution divide lateral resolution. For example, to reconstruct 8 nm x 8 nm x 8 nm from 8 nm x 8 nm x 48 nm in this tutorial, z_times should be 6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EMDiffuseConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6dee37167dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m config = EMDiffuseConfig(config='config/EMDiffuse-n.json', phase='train', \n\u001b[0m\u001b[1;32m      2\u001b[0m                          path='./dataset/EMDiffuse_dataset_demo/brain_train/zoom/train_wf', batch_size=16, mean=2)\n\u001b[1;32m      3\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPraser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Parse the config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'world_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EMDiffuseConfig' is not defined"
     ]
    }
   ],
   "source": [
    "config = EMDiffuseConfig(config='config/vEMDiffuse-i.json', phase='train', \n",
    "                         path='./dataset/EMDiffuse_dataset_demo/brain_train/zoom/train_wf', batch_size=16, mean=2, z_times=6)\n",
    "opt = Praser.parse(config) # Parse the config\n",
    "opt['world_size'] = 1 \n",
    "Util.set_seed(opt['seed'])\n",
    "print(opt['distributed'])\n",
    "model = create_EMDiffuse(opt)\n",
    "print(f'length of training data loader: {len(model.phase_loader)}, length of validation dataloader: {len(model.val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
